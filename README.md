# ğŸ­ SIRENE Data Pipeline

## ğŸ¯ Objectif & Description
Ce projet python implÃ©mente un pipeline ETL (Extract, Transform, Load) conÃ§u pour traiter les donnÃ©es massives du rÃ©pertoire SIRENE (Insee).

Le pipeline convertit des millions de lignes brutes en une Table enrichie et en KPIs, en appliquant des filtres mÃ©tiers (ex: focus Ãle-de-France) et une validation rigoureuse de la qualitÃ© des donnÃ©es.

## âš™ï¸ Installation
Ce projet utilise uv pour une gestion extrÃªmement rapide de l'environnement et des dÃ©pendances.

1. Cloner le projet :
    ```
   git clone https://github.com/apotexier/projet_sirene.git
   cd projet_sirene
    ```

2. Synchroniser l'environnement :
   ```
   uv sync
   ```

## ğŸ“‚ Architecture du Projet

Le projet est structurÃ© de maniÃ¨re modulaire pour sÃ©parer la logique de traitement, la configuration et les donnÃ©es. Voici le dÃ©tail de l'arborescence :

| Dossier / Fichier | Description |
| :--- | :--- |
| **`.venv/`** | Environnement virtuel isolÃ© contenant les 111 packages gÃ©rÃ©s par **uv**. |
| **`data/`** | Stockage local des donnÃ©es structurÃ© selon l'architecture Medallion (**bronze**, **silver**, **gold**). |
| **`docs/`** | Contient la documentation technique et le support de prÃ©sentation (Pipeline SIRENE.pptx). |
| **`notebooks/`** | Travaux d'exploration des donnÃ©es et prototypage des calculs SQL DuckDB. |
| **`scripts/`** | Utilitaires de maintenance : `check_quality.py` (Linting/Typage) et `check_gold.py` (Validation des KPIs). |
| **`src/`** | CÅ“ur du pipeline : contient les dÃ©finitions des jobs pour chaque couche et les services mÃ©tier. |
| **`tests/`** | Suite de tests unitaires et d'intÃ©gration validant l'idempotence et la logique des KPIs via **Pytest**. |
| **`.env`** | Fichier de variables d'environnement (ex: `ENV_FOR_DYNACONF`) pour basculer entre Prod et Dev. |
| **`pyproject.toml`** | Configuration centrale du projet (dÃ©pendances, outils Ruff, Mypy et Pytest). |
| **`uv.lock`** | Empreinte exacte des dÃ©pendances pour garantir la reproductibilitÃ© sur n'importe quelle machine. |
| **`README.md`** | Guide d'installation et documentation gÃ©nÃ©rale du projet. |
Le projet suit l'architecture Medallion, garantissant une traÃ§abilitÃ© totale :

ğŸ¥‰ Bronze (Raw) : Ingestion incrÃ©mentale des fichiers Parquet originaux.

ğŸ¥ˆ Silver (Cleaned) : Nettoyage, typage strict, enrichissement (calcul d'Ã¢ge, secteurs) et validation de schÃ©mas via Pandera.

ğŸ¥‡ Gold (Analytics) : Jointures et agrÃ©gations SQL avec DuckDB pour gÃ©nÃ©rer les KPIs.

#### ğŸ› ï¸ Stack Technique

* Moteur de calcul : DuckDB 
  
* Cleaning & Validation : Pandera & Pandas

* Configuration : Dynaconf (Gestion multi-environnements)

* environnement de projet : uv (Ultra-fast Python bundler)

* Logs : Loguru

* Test : pytest

* Stockage : parquet

#### ğŸï¸ Environnements
Le comportement du pipeline se configure via le fichier .env Ã  la racine :

* Production **(ENV_FOR_DYNACONF=production)** : Traitement complet des donnÃ©es.

* DÃ©veloppement **(ENV_FOR_DYNACONF=development)** : Utilise la sample_limit dÃ©finie dans *config/settings.toml* pour des tests rapides.

### ğŸ§± Lancer le pipeline complet

ExÃ©cutez l'ensemble du cycle de donnÃ©es de bout en bout :
```bash
uv run python -m sirene_pipeline.main
```

### ğŸ‘Œ QualitÃ© du code et Tests
Le projet impose des standards de qualitÃ© automatisÃ©s :
* Linting & Formatage : lancer le fichier check_quality.py

* Test : lancer pytest dans le dossier *tests*


### ğŸ’¾ Auteur:
*atexier - FÃ©vrier 2026*